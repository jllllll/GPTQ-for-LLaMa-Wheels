# GPTQ-for-LLaMa-Wheels
Precompiled Linux x86_64 Wheels for GPTQ-for-LLaMa CUDA  
See the [main branch](https://github.com/jllllll/GPTQ-for-LLaMa-Wheels) for Windows AMD64 wheels.

--------------------------

Wheels in root directory compiled from [oobabooga's fork](https://github.com/oobabooga/GPTQ-for-LLaMa)
- Supports Pascal+ (compute 6.0+)

832e220 wheels compiled from latest (as of writing) commit of [GPTQ-for-LLaMa](https://github.com/qwopqwop200/GPTQ-for-LLaMa/tree/cuda)

0cc4m wheels compiled from [0cc4m's fork](https://github.com/0cc4m/GPTQ-for-LLaMa) for [KoboldAI](https://github.com/0cc4m/KoboldAI)
- Supports late-Kepler+ (compute 3.5+)

**Wheels are compiled using GitHub Actions.**

--------------------------

Intended for use with:  
[text-generation-webui](https://github.com/oobabooga/text-generation-webui)  
[KoboldAI](https://github.com/0cc4m/KoboldAI)
